{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6b9e76",
   "metadata": {},
   "source": [
    "## G -Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97edf0c",
   "metadata": {},
   "source": [
    "### Imports\n",
    "*Initialize the environment and the Linear Regression class*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4a13df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lin_reg import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "datafile = \"housing.csv\"\n",
    "model = LinearRegression()\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=100)\n",
    "\n",
    "data = np.genfromtxt(datafile, delimiter=\",\", names=True, dtype=None, \n",
    "                     encoding=\"utf-8\",  missing_values=\"\", filling_values=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be8bbe2",
   "metadata": {},
   "source": [
    "### Cleaning & Organizing\n",
    "*Remove incomplete rows*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c411a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_y = \"median_house_value\"\n",
    "num_features = [\n",
    "    \"longitude\", \"latitude\", \"housing_median_age\", \n",
    "    \"total_rooms\", \"total_bedrooms\", \"population\", \n",
    "    \"households\", \"median_income\"\n",
    "]\n",
    "cat_features = [\"ocean_proximity\"]\n",
    "all_features = [target_y] + num_features + cat_features\n",
    "\n",
    "mask = np.ones(len(data), dtype=bool)\n",
    "\n",
    "for col in all_features:\n",
    "    if data[col].dtype.kind in \"fi\":\n",
    "        mask &= ~np.isnan(data[col])\n",
    "    else: \n",
    "        mask &= (data[col] != \"\") & (data[col] != \"nan\")\n",
    "\n",
    "clean_data = data[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dd38e9",
   "metadata": {},
   "source": [
    "### Extra - Cleaning stats\n",
    "*Summary of the data lost during the filtering process*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0457ddd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['median_house_value: 0 missing values',\n",
       "  'longitude: 0 missing values',\n",
       "  'latitude: 0 missing values',\n",
       "  'housing_median_age: 0 missing values',\n",
       "  'total_rooms: 0 missing values',\n",
       "  'total_bedrooms: 207 missing values',\n",
       "  'population: 0 missing values',\n",
       "  'households: 0 missing values',\n",
       "  'median_income: 0 missing values',\n",
       "  'ocean_proximity: 0 missing values'],\n",
       " {'Total rows before': 20640,\n",
       "  'Total rows remaining': 20433,\n",
       "  'Total rows lost': 207})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_results = []\n",
    "for col in all_features:\n",
    "    if data[col].dtype.kind in \"fi\":\n",
    "        missing_count = np.sum(np.isnan(data[col]))\n",
    "    else:\n",
    "        missing_count = np.sum((data[col] == \"\") | (data[col] == \"nan\"))\n",
    "    missing_results.append(f\"{col}: {missing_count} missing values\")\n",
    "(missing_results, {\n",
    "    \"Total rows before\": len(data),\n",
    "    \"Total rows remaining\": len(clean_data),\n",
    "    \"Total rows lost\": len(data) - len(clean_data)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88fb6e0",
   "metadata": {},
   "source": [
    "### Categorical Features\n",
    "*Transform text-based location data into binary numerical features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3900958e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20433, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cats = np.unique(clean_data[\"ocean_proximity\"])\n",
    "\n",
    "cats_to_encode = unique_cats[:-1]\n",
    "encoded_list = []\n",
    "\n",
    "for cat in cats_to_encode:\n",
    "    binary_col = np.zeros(len(clean_data))\n",
    "    \n",
    "    for i in range(len(clean_data)):\n",
    "        if clean_data[\"ocean_proximity\"][i] == cat:\n",
    "            binary_col[i] = 1\n",
    "    \n",
    "    encoded_list.append(binary_col)\n",
    "\n",
    "ocean_encoded = np.column_stack(encoded_list)\n",
    "ocean_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e44f11",
   "metadata": {},
   "source": [
    "### Preparing the data for the model\n",
    "*Constructing the feature matrix X and the target vector y*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78d0b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = clean_data[target_y]\n",
    "num_cols = []\n",
    "for feature in num_features:\n",
    "    num_cols.append(clean_data[feature])\n",
    "X_num = np.column_stack(num_cols)\n",
    "\n",
    "X_all = np.hstack([X_num, ocean_encoded])\n",
    "intercept = np.ones(len(y))\n",
    "X = np.column_stack([intercept, X_all])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a799f81",
   "metadata": {},
   "source": [
    "### Train and use the model\n",
    "*Executing the OLS fit and calculating standard error metrics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0549f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n (sample size): 20433',\n",
       " 'd (features): 12',\n",
       " 'Variance (σ²): 4713776929.50',\n",
       " 'Standard Deviation: 68656.95',\n",
       " 'RMSE: 68635.11']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y)\n",
    "\n",
    "variance = model.variance_calc(X,y)\n",
    "std_dev = model.st_dev_calc(X,y)\n",
    "rmse = model.rmse_calc(X,y)\n",
    "\n",
    "[\n",
    "    f\"n (sample size): {model.n}\",\n",
    "    f\"d (features): {model.d}\",\n",
    "    f\"Variance (σ²): {variance:.2f}\",\n",
    "    f\"Standard Deviation: {std_dev:.2f}\",\n",
    "    f\"RMSE: {rmse:.2f}\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eff3704",
   "metadata": {},
   "source": [
    "## VG Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c7a179",
   "metadata": {},
   "source": [
    "### $R^2$\n",
    "*Evaluating how much of the variation in house prices the model explains.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54fa2ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R-squared: 0.6465'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_squared = model.r_squared_calc(X,y)\n",
    "f\"R-squared: {r_squared:.4f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9f692",
   "metadata": {},
   "source": [
    "### F-Statistic & p-value\n",
    "*Testing if the group of predictors together helps predict price better than using no predictors.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46bc88c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F-Statistic': 3111.61, 'p-value': '0.0000000000'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_stat, p_value = model.f_test(X,y)\n",
    "{\n",
    "    \"F-Statistic\": round(float(f_stat), 2),\n",
    "    \"p-value\": f\"{float(p_value):.10f}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47df52a",
   "metadata": {},
   "source": [
    "### Pearson Correlation\n",
    "*Analyzing linear relationships between feature pairs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0defddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude           : [ 1.   -0.92 -0.11  0.05  0.07  0.1   0.06 -0.02  0.32 -0.06  0.01 -0.47]',\n",
       " 'latitude            : [-0.92  1.    0.01 -0.04 -0.07 -0.11 -0.07 -0.08 -0.45  0.35 -0.02  0.36]',\n",
       " 'housing_median_age  : [-0.11  0.01  1.   -0.36 -0.32 -0.3  -0.3  -0.12  0.05 -0.24  0.02  0.26]',\n",
       " 'total_rooms         : [ 0.05 -0.04 -0.36  1.    0.93  0.86  0.92  0.2  -0.    0.03 -0.01 -0.02]',\n",
       " 'total_bedrooms      : [ 0.07 -0.07 -0.32  0.93  1.    0.88  0.98 -0.01  0.02 -0.01 -0.   -0.02]',\n",
       " 'population          : [ 0.1  -0.11 -0.3   0.86  0.88  1.    0.91  0.01  0.07 -0.02 -0.01 -0.06]',\n",
       " 'households          : [ 0.06 -0.07 -0.3   0.92  0.98  0.91  1.    0.01  0.04 -0.04 -0.01 -0.01]',\n",
       " 'median_income       : [-0.02 -0.08 -0.12  0.2  -0.01  0.01  0.01  1.    0.17 -0.24 -0.01  0.06]',\n",
       " 'ocean_<1H           : [ 0.32 -0.45  0.05 -0.    0.02  0.07  0.04  0.17  1.   -0.61 -0.01 -0.31]',\n",
       " 'ocean_INLAND        : [-0.06  0.35 -0.24  0.03 -0.01 -0.02 -0.04 -0.24 -0.61  1.   -0.01 -0.24]',\n",
       " 'ocean_ISLAND        : [ 0.01 -0.02  0.02 -0.01 -0.   -0.01 -0.01 -0.01 -0.01 -0.01  1.   -0.01]',\n",
       " 'ocean_NEAR_BAY      : [-0.47  0.36  0.26 -0.02 -0.02 -0.06 -0.01  0.06 -0.31 -0.24 -0.01  1.  ]',\n",
       " '                        LON   LAT   AGE   RMS   BED   POP   HHD   INC   <1H   INL   ISL   BAY']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson = model.pearson_corr(X)\n",
    "feature_names = ['intercept', 'longitude', 'latitude', 'housing_median_age', \n",
    "                 'total_rooms', 'total_bedrooms', 'population', 'households',\n",
    "                 'median_income', 'ocean_<1H', 'ocean_INLAND', 'ocean_ISLAND', \n",
    "                 'ocean_NEAR_BAY']\n",
    "short_names = [\"LON\", \"LAT\", \"AGE\", \"RMS\", \"BED\", \"POP\", \"HHD\", \"INC\", \"<1H\", \"INL\", \"ISL\", \"BAY\"]\n",
    "rows = [f\"{feature_names[i+1]:20s}: {pearson[i]}\" for i in range(len(pearson))]\n",
    "\n",
    "footer = \" \" * 24 + \"   \".join(short_names)\n",
    "rows.append(footer)\n",
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b17e0",
   "metadata": {},
   "source": [
    "### Discussion : Collinearity and parameters selection\n",
    "The Pearson correlation table shows that several predictors share very similar information. The strongest group is formed by the housing related variables: **total_bedrooms** correlates  with **households** at 0.98,**total_rooms** with **total_bedrooms** at 0.93, and with **households** at 0.92. These values are extremely high, which means these variables move almost in lockstep. **Population** is also closely tied to this group, with correlations above 0.85 with all 3 of them. Together, these four variables describe nearly the same underlying pattern in the dataset.\n",
    "\n",
    "There is also a very strong relationship between the geographic variables longitude and latitude (−0.92). This indicates that the locations in the dataset follow a narrow diagonal pattern, so the two coordinates do not vary independently.\n",
    "\n",
    "**Statistical Impact:**\n",
    "When predictors are highly correlated, the variance-covariance matrix c = (X^T X)^(-1)σ² \n",
    "has inflated diagonal elements (cᵢᵢ). Since SE(B̂ᵢ) = σ̂ √cᵢᵢ, this directly increases \n",
    "standard errors. The model struggles to solve (X^T X)b = X^T y reliably when X^T X is \n",
    "near-singular due to collinearity.\n",
    "\n",
    "Because these predictors overlap so much, the model cannot fully separate their individual effects. When several variables carry almost the same information, the coefficient of one variable can easily change sign depending on which of the others are included. This explains why total_rooms appears with the “wrong” sign: the model is trying to distribute a shared signal across several nearly identical predictors, and the sign becomes unstable as a result. This behaviour is typical in the presence of strong collinearity and does not mean that the variable has a genuinely negative relationship with the outcome.\n",
    "\n",
    "These correlations do not create a statistical hierarchy in the regression sense. A statistical hierarchy would require keeping certain variables because they appear inside interaction terms or polynomial terms. Here, the predictors are correlated, but none of them are mathematically built from the others. The correlations therefore do not force any variable to remain in the model for hierarchical reasons.\n",
    "Statistical hierarchy applies when:\n",
    "- Interaction: Y = β₀ + β₁X₁ + β₂X₂ + β₃X₁X₂ (must keep X₁, X₂ if X₁X₂ is significant)\n",
    "- Polynomial: Y = β₀ + β₁X + β₂X² (must keep X if X² is significant)\n",
    "\n",
    "Our model has only raw variables, so no hierarchical constraint applies.\n",
    "The housing variables do reflect different levels of the same structure which explains why they correlate so strongly. This structure justifies including them initially if the goal is to describe the housing environment in detail. However, their strong overlap limits how separately their coefficients can be interpreted. The unusual sign of total_rooms is a direct consequence of this overlap rather than a meaningful effect.\n",
    "\n",
    "In short, the Pearson correlations show strong collinearity but no statistical hierarchy that forces us to keep variables in the model. The housing variables form a tightly connected cluster, which justifies their initial inclusion, but their overlap explains both the instability of coefficients and the unexpected sign of total_rooms. If the goal is clearer and more stable effects, simplifying this group is appropriate; if the goal is descriptive detail, the variables can be kept, as long as their dependence is acknowledged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589041ae",
   "metadata": {},
   "source": [
    "### T-tests\n",
    "*Testing whether a single predictor has a real effect on price (different from zero).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7c93ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['intercept           : -25.6395, 0.000000',\n",
       " 'longitude           : -26.2963, 0.000000',\n",
       " 'latitude            : -25.3629, 0.000000',\n",
       " 'housing_median_age  :  24.4389, 0.000000',\n",
       " 'total_rooms         :  -7.8250, 0.000000',\n",
       " 'total_bedrooms      :  14.6402, 0.000000',\n",
       " 'population          : -35.2824, 0.000000',\n",
       " 'households          :   6.6589, 0.000000',\n",
       " 'median_income       : 116.1510, 0.000000',\n",
       " 'ocean_<1H           :  -2.7258, 0.006421',\n",
       " 'ocean_INLAND        : -19.3633, 0.000000',\n",
       " 'ocean_ISLAND        :   4.8327, 0.000001',\n",
       " 'ocean_NEAR_BAY      :  -3.7835, 0.000155']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_stats, p_values = model.t_tests(X,y)\n",
    "results =  []\n",
    "\n",
    "\n",
    "for i in range(len(t_stats)):\n",
    "    sig = \"Significant\" if p_values[i] <0.05 else \"NOT significant\"\n",
    "    results.append(f\"{feature_names[i]:20s}: {t_stats[i]:8.4f}, {p_values[i]:.6f}\")\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f568a1",
   "metadata": {},
   "source": [
    "All predictors in the fitted model are statistically detectable at the 5% level (every predictor’s p‑value < 0.05). The t‑tests identify a set of variables that the model finds informative for predicting house price in this sample.\n",
    "With a sample size of 20,433, even small effects are easily detected as statistically significant, so the p-values alone don't indicate which predictors are most important—the t-statistics provide better ranking of effect strength.\n",
    "\n",
    "The strongest evidence is for **median_income** (t = 116.15, p < 0.001), which shows a very large positive association with house price in the sample;\n",
    "\n",
    "**population** (t = −35.28, p < 0.001) shows a strong negative association; \n",
    "\n",
    "**longitude** (t = −26.30, p < 0.001) and **latitude** (t = −25.36, p < 0.001) both show large negative associations in this fit, and \n",
    "\n",
    "**housing_median_age** (t = 24.44, p < 0.001) also has a strong positive association. \n",
    "\n",
    "**total_rooms** has a negative t (t = −7.83) in the original model despite an intuitive expectation of a positive effect; \n",
    "This can be because of thr high overlapping data with *total_bedrooms*, *households* and *population* as we've seen in the Paerson correlation table. This can cause instability in individual coefficients resulting in imprecise values or signs. \n",
    "\n",
    "Among the categorical proximity indicators, **ocean_INLAND** is strongly negative (t = −19.3633, p < 0.001), **ocean_ISLAND** is positive (t = 4.8327, p < 0.001), **ocean_NEAR_BAY** is negative (t = −3.7835, p ≈ 0.00016), and **ocean_<1H** is detectable with weaker evidence (t = −2.7258, p ≈ 0.0064). \n",
    "\n",
    "*Confidence intervals (in the next cell) agree with the t‑tests: none include zero, which supports the significance results above.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c72f4",
   "metadata": {},
   "source": [
    "### Confidence Intervals\n",
    "*Gives a plausible range for the true effect of a predictor; if the range does not include zero, the effect is detectable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d4477ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intercept': {'Lower': -2438881.36, 'Upper': -2092470.6},\n",
       " 'longitude': {'Lower': -28811.59, 'Upper': -24814.39},\n",
       " 'latitude': {'Lower': -27451.48, 'Upper': -23512.89},\n",
       " 'housing_median_age': {'Lower': 986.5, 'Upper': 1158.54},\n",
       " 'total_rooms': {'Lower': -7.74, 'Upper': -4.64},\n",
       " 'total_bedrooms': {'Lower': 87.09, 'Upper': 114.02},\n",
       " 'population': {'Lower': -40.08, 'Upper': -35.86},\n",
       " 'households': {'Lower': 35.01, 'Upper': 64.22},\n",
       " 'median_income': {'Lower': 38597.06, 'Upper': 39922.09},\n",
       " 'ocean_<1H': {'Lower': -7354.53, 'Upper': -1201.74},\n",
       " 'ocean_INLAND': {'Lower': -47972.11, 'Upper': -39152.75},\n",
       " 'ocean_ISLAND': {'Lower': 88344.04, 'Upper': 208903.57},\n",
       " 'ocean_NEAR_BAY': {'Lower': -12496.91, 'Upper': -3967.47}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower, upper = model.confidence_interval(X,y,alpha=0.05)\n",
    "ci_table = {}\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    ci_table[feature_names[i]] = {\n",
    "        \"Lower\": round(lower[i], 2),\n",
    "        \"Upper\": round(upper[i], 2)\n",
    "    }\n",
    "\n",
    "ci_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aeca47",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804695fd",
   "metadata": {},
   "source": [
    "### Discussion on confidence Levels:\n",
    "\n",
    "For this analysis, I use a 95% confidence level (α=0.05). This indicates that I am accepting a 5% risk of a Type I error, specifically, the risk of rejecting the null hypothesis (concluding a coefficient is significant) when it is actually zero in the population.\n",
    "\n",
    "Since the model has R² = 0.65, it explains a reasonable portion of the variation \n",
    "in house prices but leaves 35% unexplained. This moderate fit supports using the \n",
    "standard 95% level—it's strict enough to avoid false conclusions but not so strict \n",
    "that the intervals become too wide to be useful. \n",
    "\n",
    "A 90% level would make the intervals narrower but less reliable, while a 99% level would make them so wide that it becomes difficult to draw useful conclusions. A 95% level provides a reasonable balance between these two extremes.\n",
    "\n",
    "Looking at the resulting confidence intervals, a few predictors stand out as clearly influential. Median_income has a strongly positive interval(38597,  39922), which shows that higher income is associated with higher predicted prices. Several location related variables also show stable effects: both longitude and latitude have negative intervals, indicating a relationship between location and price in the dataset. Among the categorical variables, ocean_ISLAND has a large positive interval (88344,  208903), while ocean_INLAND shows a clear negative effect(-47972.11, -39152.75).\n",
    "\n",
    "Other predictors have smaller but still consistent intervals. For example, total_rooms and population both have narrow negative intervals, suggesting small downward effects. Total_bedrooms and households show modest positive intervals. These effects are weaker than the main predictors but still statistically meaningful since their intervals do not cross zero.\n",
    "\n",
    "The width of each interval reflects how precisely the coefficient is estimated: narrower intervals indicate more certainty, while wider ones show more uncertainty. Since none of the intervals include zero, each predictor shows a statistically reliable direction of effect at the chosen confidence level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd9eeb",
   "metadata": {},
   "source": [
    "### Extra - Analyzing high correlations:\n",
    "*Highest multicollinearity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73d24135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['total_bedrooms & households        : 0.98',\n",
       " 'total_rooms    & total_bedrooms    : 0.93',\n",
       " 'longitude      & latitude          : -0.92',\n",
       " 'total_rooms    & households        : 0.92',\n",
       " 'population     & households        : 0.91',\n",
       " 'total_bedrooms & population        : 0.88',\n",
       " 'total_rooms    & population        : 0.86']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = model.pearson_corr(X)\n",
    "actual_features = feature_names[1:]\n",
    "high_corr_list = []\n",
    "\n",
    "for i in range(len(actual_features)):\n",
    "    for j in range(i + 1, len(actual_features)):\n",
    "        correlation = corr_matrix[i, j]\n",
    "        if abs(correlation) > 0.85:\n",
    "            high_corr_list.append((actual_features[i], actual_features[j], correlation))\n",
    "\n",
    "high_corr_list.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "[f\"{feat_a:14s} & {feat_b:18s}: {val:.2f}\" for feat_a, feat_b, val in high_corr_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af71607d",
   "metadata": {},
   "source": [
    "*Highest significance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c9f4dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['median_income      |     116.15',\n",
       " 'population         |      35.28',\n",
       " 'longitude          |      26.30',\n",
       " 'latitude           |      25.36',\n",
       " 'housing_median_age |      24.44']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_stats, _ = model.t_tests(X, y)\n",
    "\n",
    "impact_list = []\n",
    "for i in range(1, len(feature_names)):\n",
    "    impact_list.append((feature_names[i], abs(t_stats[i])))\n",
    "\n",
    "impact_list.sort(key=lambda x: x[1], reverse=True)\n",
    "[f\"{name:18s} | {val:10.2f}\" for name, val in impact_list[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c8de3e",
   "metadata": {},
   "source": [
    "### Extra - Refined Model demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "436ce5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unrefined RMSE: 68635.11',\n",
       " 'Unrefined Variance (σ²): 4713776929.50',\n",
       " 'Refined RMSE: 70690.98',\n",
       " 'Refined Variance (σ²): 4999906984.29']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_indices = [0,1,2,3,4,6,8,9,10,11,12]\n",
    "X_refined = X[:, refined_indices]\n",
    "\n",
    "model_refined = LinearRegression()\n",
    "model_refined.fit(X_refined, y)\n",
    "\n",
    "[\n",
    " f\"Unrefined RMSE: {rmse:.2f}\" , \n",
    " f\"Unrefined Variance (σ²): {variance:.2f}\",  \n",
    " f\"Refined RMSE: {model_refined.rmse_calc(X_refined, y):.2f}\", \n",
    " f\"Refined Variance (σ²): {model_refined.variance_calc(X_refined, y):.2f}\"\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd6498a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--- ORIGINAL MODEL ---',\n",
       " 'intercept           : -25.6395, 0.000000',\n",
       " 'longitude           : -26.2963, 0.000000',\n",
       " 'latitude            : -25.3629, 0.000000',\n",
       " 'housing_median_age  :  24.4389, 0.000000',\n",
       " 'total_rooms         :  -7.8250, 0.000000',\n",
       " 'total_bedrooms      :  14.6402, 0.000000',\n",
       " 'population          : -35.2824, 0.000000',\n",
       " 'households          :   6.6589, 0.000000',\n",
       " 'median_income       : 116.1510, 0.000000',\n",
       " 'ocean_<1H           :  -2.7258, 0.006421',\n",
       " 'ocean_INLAND        : -19.3633, 0.000000',\n",
       " 'ocean_ISLAND        :   4.8327, 0.000001',\n",
       " 'ocean_NEAR_BAY      :  -3.7835, 0.000155',\n",
       " '',\n",
       " '--- REFINED MODEL ---',\n",
       " 'intercept           : -25.9566, 0.000000',\n",
       " 'longitude           : -27.0413, 0.000000',\n",
       " 'latitude            : -26.2918, 0.000000',\n",
       " 'housing_median_age  :  22.2453, 0.000000',\n",
       " 'total_rooms         :  30.6387, 0.000000',\n",
       " 'population          : -27.5044, 0.000000',\n",
       " 'median_income       : 111.6947, 0.000000',\n",
       " 'ocean_<1H           :  -2.4349, 0.014905',\n",
       " 'ocean_INLAND        : -22.0366, 0.000000',\n",
       " 'ocean_ISLAND        :   4.6955, 0.000003',\n",
       " 'ocean_NEAR_BAY      :  -2.3779, 0.017419']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_stats_ref, p_values_ref = model_refined.t_tests(X_refined, y)\n",
    "ref_feature_names = [\n",
    "    'intercept', 'longitude', 'latitude', 'housing_median_age', \n",
    "    'total_rooms', 'population', 'median_income', \n",
    "    'ocean_<1H', 'ocean_INLAND', 'ocean_ISLAND', 'ocean_NEAR_BAY'\n",
    "]\n",
    "\n",
    "original_results = [\"--- ORIGINAL MODEL ---\"]\n",
    "for i in range(len(t_stats)):\n",
    "        original_results.append(f\"{feature_names[i]:20s}: {t_stats[i]:8.4f}, {p_values[i]:.6f}\")\n",
    "refined_results = [\"--- REFINED MODEL ---\"]\n",
    "for i in range(len(t_stats_ref)):\n",
    "        refined_results.append(f\"{ref_feature_names[i]:20s}: {t_stats_ref[i]:8.4f}, {p_values_ref[i]:.6f}\")\n",
    "\n",
    "comparison = original_results + [\"\"] + refined_results\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c1dd91",
   "metadata": {},
   "source": [
    "The refined model confirms that the unusual behaviour in the original regression was caused by multicollinearity. When several predictors describe almost the same underlying pattern, the model cannot assign their effects independently, and the coefficients become unstable. This is why total_rooms appeared with a negative sign despite representing a feature that should logically increase housing value. After removing the most overlapping variables (total_bedrooms and households), the remaining predictors no longer compete for the same signal, and total_rooms returns to a positive and more interpretable effect.\n",
    "\n",
    "The refined model has a slightly higher RMSE and variance, which means its predictions are less precise. This happens because removing redundant predictors reduces the model’s ability to “fit” the sample perfectly. However, the trade‑off is beneficial for interpretation. The refined model produces coefficients that are more stable, easier to interpret, and less influenced by noise introduced by collinearity. For understanding how each predictor relates to housing prices, the refined model is therefore the more trustworthy one, while the full model remains better only for raw predictive accuracy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
